# NGINX deployment with ngx-inference module for reference EPP testing
# ConfigMap is generated dynamically by setup.sh and test-kind.sh using generate-config.sh
apiVersion: v1
kind: Service
metadata:
  name: nginx-inference
  namespace: ngx-inference-test
  labels:
    app: nginx-inference
spec:
  type: NodePort
  selector:
    app: nginx-inference
  ports:
    - port: 8082
      targetPort: 8082
      nodePort: 30080
      protocol: TCP
      name: http
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-inference
  namespace: ngx-inference-test
  labels:
    app: nginx-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx-inference
  template:
    metadata:
      labels:
        app: nginx-inference
    spec:
      containers:
        - name: nginx
          # Built from docker/nginx/Dockerfile and loaded into kind
          image: ngx-inference:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 8082
              name: http
          volumeMounts:
            - name: nginx-config
              mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
            - name: epp-tls-cert
              mountPath: /etc/epp-tls
              readOnly: true
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "500m"
          readinessProbe:
            httpGet:
              path: /health
              port: 8082
            initialDelaySeconds: 5
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /health
              port: 8082
            initialDelaySeconds: 10
            periodSeconds: 10
      volumes:
        - name: nginx-config
          configMap:
            name: nginx-inference-bbr-on-epp-on  # Initial ConfigMap, updated by test-kind.sh
        - name: epp-tls-cert
          secret:
            secretName: epp-tls-secret
