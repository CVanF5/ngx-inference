# Standalone NGINX deployment with ngx-inference module for reference EPP testing
# This bypasses NGF and directly tests the module against the real reference EPP
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-inference-config
  namespace: ngx-inference-test
data:
  nginx.conf: |
    # NGINX configuration for ngx-inference module testing with reference EPP
    load_module /usr/lib/nginx/modules/libngx_inference.so;

    events {
        worker_connections 1024;
    }

    http {
        include /etc/nginx/mime.types;
        default_type application/octet-stream;

        # Logging
        log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for" '
                        'upstream: $inference_upstream';

        access_log /var/log/nginx/access.log main;
        error_log /var/log/nginx/error.log debug;

        sendfile on;
        keepalive_timeout 65;

        # Use Kubernetes DNS for dynamic resolution
        # This allows NGINX to start even if upstream hosts aren't ready yet
        # Using the standard kube-dns service ClusterIP
        resolver 10.96.0.10 valid=10s;
        resolver_timeout 5s;

        server {
            listen 8081;
            server_name _;

            # Health check endpoint
            location /health {
                access_log off;
                return 200 "healthy\n";
                add_header Content-Type text/plain;
            }

            # Test endpoint using reference EPP for endpoint selection
            location /v1/chat/completions {
                # Enable EPP for endpoint selection
                inference_epp on;
                # Reference EPP service endpoint (deployed via helm)
                inference_epp_endpoint "vllm-llama3-8b-instruct-epp.ngx-inference-test.svc.cluster.local:9002";
                inference_epp_timeout_ms 5000;
                inference_epp_failure_mode_allow off;
                # Use Gateway API standard header name
                inference_epp_header_name "x-gateway-destination-endpoint";
                
                # TLS configuration for EPP connection with trusted certificate
                inference_epp_tls on;
                inference_epp_ca_file /etc/epp-tls/tls.crt;

                # Proxy to the upstream selected by EPP
                proxy_pass http://$inference_upstream$request_uri;
                
                # Standard proxy headers
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                
                # Increase timeouts for AI inference
                proxy_connect_timeout 60s;
                proxy_send_timeout 300s;
                proxy_read_timeout 300s;
            }


        }
    }
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-inference
  namespace: ngx-inference-test
  labels:
    app: nginx-inference
spec:
  type: NodePort
  selector:
    app: nginx-inference
  ports:
    - port: 80
      targetPort: 8081
      nodePort: 30080
      protocol: TCP
      name: http
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-inference
  namespace: ngx-inference-test
  labels:
    app: nginx-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx-inference
  template:
    metadata:
      labels:
        app: nginx-inference
    spec:
      containers:
        - name: nginx
          # Built from docker/nginx/Dockerfile and loaded into kind
          image: ngx-inference:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 8081
              name: http
          volumeMounts:
            - name: nginx-config
              mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
            - name: epp-tls-cert
              mountPath: /etc/epp-tls
              readOnly: true
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "500m"
          readinessProbe:
            httpGet:
              path: /health
              port: 8081
            initialDelaySeconds: 5
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /health
              port: 8081
            initialDelaySeconds: 10
            periodSeconds: 10
      volumes:
        - name: nginx-config
          configMap:
            name: nginx-inference-config
        - name: epp-tls-cert
          secret:
            secretName: epp-tls-secret
