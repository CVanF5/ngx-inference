server {
    listen 8081;
    listen 80;
    server_name localhost;

    # vLLM Chat Completions API with BBR only (EPP disabled)
    location /v1/chat/completions {
        inference_bbr on;
        inference_bbr_max_body_size 52428800; # 50MB limit for AI workloads
        inference_bbr_header_name X-Gateway-Model-Name;
        inference_bbr_default_model "meta-llama/Llama-3.1-8B-Instruct";
        inference_bbr_failure_mode_allow off;

        set $backend "echo-server.ngx-inference-test.svc.cluster.local:80";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass http://$backend;
    }

    # vLLM Models API with BBR only (EPP disabled)
    location /v1/models {
        inference_bbr on;
        inference_bbr_max_body_size 52428800; # 50MB limit for AI workloads
        inference_bbr_header_name X-Gateway-Model-Name;
        inference_bbr_default_model "meta-llama/Llama-3.1-8B-Instruct";
        inference_bbr_failure_mode_allow off;

        set $backend "echo-server.ngx-inference-test.svc.cluster.local:80";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass http://$backend;
    }

    # BBR enabled, EPP disabled
    location /bbr-test {
        inference_bbr on;
        inference_bbr_max_body_size 10485760; # 10MB
        inference_bbr_header_name X-Gateway-Model-Name;
        inference_bbr_default_model "test-model";
        inference_bbr_failure_mode_allow off;

        set $backend "localhost:8080";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass http://$backend;
    }

    location /epp-test {
        # EPP disabled - just proxy without EPP processing
        set $backend "localhost:8080";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass http://$backend;
    }

    location /responses {
        # BBR enabled, EPP disabled
        inference_bbr on;
        inference_bbr_max_body_size 52428800; # 50MB limit for AI workloads
        inference_bbr_default_model "gpt-4";

        set $backend "localhost:8080";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass http://$backend;
    }

    location /health {
        return 200 "OK\n";
        add_header Content-Type text/plain;
    }

    location / {
        set $backend "localhost:8080";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_pass http://$backend;
    }
}
